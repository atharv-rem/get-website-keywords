import ollama 
import json
import openpyxl
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter

#load the meta description data and running ollama to get keywords and og image links
with open('scraper\scraper\meta_desc.json', 'r') as file:
    data = json.load(file)
    file_path = r"C:\Users\athar\Downloads\color database.xlsx"
    workbook = load_workbook(file_path)
    sheet = workbook.active
    print("Adding og image links to the Excel file...")

    # Add "og image" header in the next empty column
    next_col = 1
    for cell in sheet[1]:
        if cell.value:
            next_col = cell.column + 1
    sheet.cell(row=1, column=next_col, value="og image link")
    
    og_image = []
    for item in data:
        if not item.get('og_image'):
            og_image.append("No og image found")
            continue
        image = item.get('og_image')
        og_image.append(image)
    
    # Write og_image links row by row (starting from second row)
    for row_num, image in enumerate(og_image, start=2):
        sheet.cell(row=row_num, column=next_col, value=image)
    workbook.save(file_path)
    print("og image links added to the Excel file successfully.")
    
    print("Starting the keyword extraction process...")
    results = []
    tool_number = 1
    for item in data:
        print(f"Processing tool {tool_number}")
        tool_number += 1
        meta_desc = item.get('meta_description')
        if not meta_desc:
            results.append({
            "title":item.get('title'),
            "seo_keywords": "No keywords generated, meta description is empty"
            })
            continue

        try:
            response = ollama.chat(
                model='mistral',
                messages=[
                    {
                        "role": "user",
                        "content": f"Extract 5â€“10 relevant keywords from the following {meta_desc}. Only return the keywords, comma-separated, and don't include extra text. If no keywords can be found, return 'null'."
                    }
                ]
            )

            keywords = response['message']['content']
            keywords = keywords.strip().split(',')
            keywords = [keyword.strip() for keyword in keywords if keyword.strip()]
            keywords = [k for k in keywords if len(k) <= 20]
                    
            results.append({
                "title":item.get('title'),
                    "seo_keywords": keywords
            })
        except Exception as e:
            print(f"Error processing tool {tool_number}: {e}")
            results.append({
                "title": item.get('title'),
                "seo_keywords": "null"
            })

#loading the result into a json file named seo_keywords.json        
with open(r'scraper/scraper/seo_keywords.json', 'w') as f:
    json.dump(results, f, indent=4)
print("Keyword extraction completed and saved to seo_keywords.json")


# Add "SEO Keywords" header in the next empty column
next_col = 1
for cell in sheet[1]:
    if cell.value:
        next_col = cell.column + 1
sheet.cell(row=1, column=next_col, value="SEO Keywords")

# Write keywords row by row (starting from second row)
for row_num, item in enumerate(results, start=2):
    keywords = item['seo_keywords']
    if isinstance(keywords, list):
        keywords = ', '.join(keywords)
    sheet.cell(row=row_num, column=next_col, value=keywords)

# Save workbook
workbook.save(file_path)
print("Keywords added to Excel file successfully.")

